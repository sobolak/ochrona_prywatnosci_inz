# -*- coding: utf-8 -*-
"""federated_differential_epsilon.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gNybjD1XsOtIqsFoz1z4X_YyVRAmExcA
"""

!pip install --quiet --upgrade tensorflow-federated-nightly
!pip install --quiet --upgrade nest-asyncio
!pip install --quiet --upgrade tb-nightly  

import nest_asyncio
import collections
import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow_federated as tff
import tensorflow_privacy as tfp
from matplotlib import pyplot as plt
import seaborn as sns
from google.colab import drive
drive.mount('/content/drive')

nest_asyncio.apply()

@tff.federated_computation
def start():
  return 'Federated learning + differential privacy'

start()

train, test = tff.simulation.datasets.emnist.load_data(only_digits = True)

print("Type of structure:") 
train.element_type_structure

print("Number of clients in training data") 
len(train.client_ids)

print("Number of clients in testing data") 
len(test.client_ids)


figure_1 = plt.figure(figsize=(12, 7))
figure_1.suptitle('Data distribiution in first 20 clients')
for i in range(20):
  first_clients_data = train.create_tf_dataset_for_client(train.client_ids[i])
  plot_per_user = collections.defaultdict(list)
  for example in first_clients_data:
    label = example['label'].numpy()
    plot_per_user[label].append(label)
  plt.subplot(4, 5, i+1)
  plt.title('Client {}'.format(i))
  for number in range(10):
    plt.hist(
        plot_per_user[number],
        density=False,
        bins=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10])

def get_emnist_data():
  emnist_train, emnist_test = tff.simulation.datasets.emnist.load_data(
      only_digits=True)

  def element_change_expand(element):
    return collections.OrderedDict(
        x=tf.expand_dims(element['pixels'], -1), y=element['label'])

  def train_preprocess(dataset):
    return (dataset.map(element_change_expand)
                   .shuffle(buffer_size=418)
                   .repeat(1)
                   .batch(32, drop_remainder=False))

  def test_preprocess(dataset):
    return dataset.map(element_change_expand).batch(128, drop_remainder=False)

  emnist_train = emnist_train.preprocess(train_preprocess)
  emnist_test = test_preprocess(
      emnist_test.create_tf_dataset_from_all_clients())
  return emnist_train, emnist_test

emnist_train, emnist_test = get_emnist_data()

def my_model_fn():
  model = tf.keras.models.Sequential([
      tf.keras.layers.Reshape(input_shape=(28, 28, 1), target_shape=(28 * 28,)),
      tf.keras.layers.Dense(200, activation=tf.nn.relu),
      tf.keras.layers.Dense(200, activation=tf.nn.relu),
      tf.keras.layers.Dense(10)])
  return tff.learning.from_keras_model(
      keras_model=model,
      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
      input_spec=emnist_test.element_spec,
      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])

tff.backends.native.set_local_python_execution_context(clients_per_thread=10)

total_clients = len(emnist_train.client_ids)

def train(rounds, noise_multiplier, clients_per_round, input_data_frame):
  aggregation_factory = tff.learning.model_update_aggregator.dp_aggregator(
      noise_multiplier, clients_per_round)

  sampling_prob = clients_per_round / total_clients

  learning_process = tff.learning.algorithms.build_unweighted_fed_avg(
        my_model_fn,
        client_optimizer_fn=lambda: tf.keras.optimizers.SGD(0.01),
        server_optimizer_fn=lambda: tf.keras.optimizers.SGD(1.0, momentum=0.9),
        model_aggregator=aggregation_factory)

  eval_process = tff.learning.build_federated_evaluation(my_model_fn)

  state = learning_process.initialize()
  for round in range(rounds):
    if round % 2 == 0:
      model_weights = learning_process.get_model_weights(state)
      metrics = eval_process(model_weights, [emnist_test])['eval']
      print(f'Round {round:3d}: {metrics}')
      input_data_frame = input_data_frame.append({'Round': round,
                                      'NoiseMultiplier': noise_multiplier,
                                      **metrics}, ignore_index=True)
    x = np.random.uniform(size=total_clients)
    sampled_clients = [
        emnist_train.client_ids[i] for i in range(total_clients)
        if x[i] < sampling_prob]
    sampled_train_data = [
        emnist_train.create_tf_dataset_for_client(client)
        for client in sampled_clients]

    result = learning_process.next(state, sampled_train_data)
    state = result.state
    metrics = result.metrics

  model_weights = learning_process.get_model_weights(state)
  metrics = eval_process(model_weights, [emnist_test])['eval']
  print(f'Round {rounds:3d}: {metrics}')
  input_data_frame = input_data_frame.append({'Round': rounds,
                                  'NoiseMultiplier': noise_multiplier,
                                  **metrics}, ignore_index=True)

  return input_data_frame

def make_plot(data_frame):
  plt.figure(figsize=(15, 5))

  dff = data_frame.rename(
      columns={'sparse_categorical_accuracy': 'Accuracy', 'loss': 'Loss'})

  plt.subplot(121)
  sns.lineplot(data=dff, x='Round', y='Accuracy', hue='NoiseMultiplier', palette='dark')
  plt.subplot(122)
  sns.lineplot(data=dff, x='Round', y='Loss', hue='NoiseMultiplier', palette='dark')

rdp_orders = ([1.25, 1.5, 1.75, 2., 2.25, 2.5, 3., 3.5, 4., 4.5] +
              list(range(5, 64)) + [128, 256, 512])

def finding_num_of_clients(total_clients, base_noise_multiplier, base_clients_per_round, target_delta, target_eps, what):

  def get_epsilon(clients_per_round):
    q = clients_per_round / total_clients
    noise_multiplier = base_noise_multiplier
    noise_multiplier *= clients_per_round / base_clients_per_round
    rdp = tfp.compute_rdp(
        q, noise_multiplier=noise_multiplier, steps=rounds, orders=rdp_orders)
    eps, _, _ = tfp.get_privacy_spent(rdp_orders, rdp, target_delta=target_delta)
    return clients_per_round, eps, noise_multiplier

  def find_needed_clients_per_round():
    epsilon = get_epsilon(base_clients_per_round)
    if epsilon[1] < target_eps:
      return epsilon
    
    while True:
      lo = epsilon
      epsilon = get_epsilon(2 * lo[0])
      if epsilon[1] < target_eps:
        break

    while epsilon[0] - lo[0] > 1:
      mid = get_epsilon((lo[0] + epsilon[0]) // 2)
      if mid[1] > target_eps:
        lo = mid
      else:
        epsilon = mid

    return epsilon

  clients_per_round, _, noise_multiplier = find_needed_clients_per_round()
  print(f'To get ({target_eps}, {target_delta})-DP, use {clients_per_round} '
        f'clients with noise multiplier {noise_multiplier}.')
  if what == 'eps':
    return [noise_multiplier, clients_per_round]
  else:
    return [noise_multiplier, clients_per_round]

total_clients = 3383
base_noise_multiplier = 0.5
base_clients_per_round = 50
base_target_delta = 1e-5
base_target_eps = 2
rounds = 2

target_eps = [1.3, 1.4, 1.5, 1.6, 1.8, 2 ,3, 4, 5, 6, 10, 15] 
target_eps_clients = []
target_eps_noise = []

for epsilon in target_eps:
  [noise, client] = finding_num_of_clients(total_clients, base_noise_multiplier, base_clients_per_round, base_target_delta, epsilon, 'eps')
  target_eps_clients.append(client)
  target_eps_noise.append(noise)

print(target_eps_clients)
print(target_eps_noise)
print(target_eps)

data_frame_buffor = pd.DataFrame()
  data_frame_buffor = train(rounds, 1.34, 134, data_frame_buffor)

  make_plot(data_frame_buffor)

data_frame_buffor = pd.DataFrame()
  data_frame_buffor = train(rounds, 2.38, 238, data_frame_buffor)

  make_plot(data_frame_buffor)

data_frame_buffor = pd.DataFrame()
  data_frame_buffor = train(rounds, 1.87, 187, data_frame_buffor)

  make_plot(data_frame_buffor)

data_frame_buffor = pd.DataFrame()
  data_frame_buffor = train(rounds, 1.61, 161, data_frame_buffor)

  make_plot(data_frame_buffor)

data_frame_buffor = pd.DataFrame()
  data_frame_buffor = train(rounds, 1.34, 134, data_frame_buffor)

  make_plot(data_frame_buffor)

data_frame_buffor = pd.DataFrame()
  data_frame_buffor = train(rounds, 1.2, 120, data_frame_buffor)

  make_plot(data_frame_buffor)

data_frame_buffor = pd.DataFrame()
  data_frame_buffor = train(rounds, 0.9, 90, data_frame_buffor)

  make_plot(data_frame_buffor)

data_frame_buffor = pd.DataFrame()
  data_frame_buffor = train(rounds, 0.77, 77, data_frame_buffor)

  make_plot(data_frame_buffor)

data_frame_buffor = pd.DataFrame()
  data_frame_buffor = train(rounds, 0.69, 69, data_frame_buffor)

  make_plot(data_frame_buffor)

data_frame_buffor = pd.DataFrame()
  data_frame_buffor = train(rounds, 0.63, 63, data_frame_buffor)

  make_plot(data_frame_buffor)

data_frame_buffor = pd.DataFrame()
  data_frame_buffor = train(rounds, 0.5, 50, data_frame_buffor)

  make_plot(data_frame_buffor)